# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏ö‡∏ö‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏á‡πà‡∏≤‡∏¢ (Baseline Model) ‚Äî 30 ‡∏ô‡∏≤‡∏ó
## ‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå (‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏≠‡∏∞‡πÑ‡∏£)
	‚Ä¢	‡πÅ‡∏¢‡∏Å‡πÅ‡∏¢‡∏∞‡πÇ‡∏à‡∏ó‡∏¢‡πå Regression (‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç) ‡∏Å‡∏±‡∏ö Classification (‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏Å‡∏•‡∏∏‡πà‡∏°)
	‚Ä¢	‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î Baseline (‡∏ï‡∏±‡∏ß‡∏ï‡∏±‡πâ‡∏á‡∏ï‡πâ‡∏ô):
	‚Ä¢	Regression baseline: ‡∏ó‡∏≤‡∏¢‡∏Ñ‡πà‡∏≤‡∏Å‡∏•‡∏≤‡∏á (‡πÄ‡∏ä‡πà‡∏ô ‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢)
	‚Ä¢	Classification baseline: ‡∏ó‡∏≤‡∏¢ ‡∏Ñ‡∏•‡∏≤‡∏™‡∏ó‡∏µ‡πà‡∏°‡∏≤‡∏Å‡∏™‡∏∏‡∏î (majority class)
	‚Ä¢	‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏á‡πà‡∏≤‡∏¢ ‡πÜ: Linear Regression ‡πÅ‡∏•‡∏∞ Logistic Regression
	‚Ä¢	‡∏´‡∏•‡∏±‡∏Å‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô: Train/Test Split ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏à‡∏≥ (overfitting) 
 
 ## ‡∏ó‡∏§‡∏©‡∏é‡∏µ‡∏™‡∏±‡πâ‡∏ô ‡πÜ
	‚Ä¢	Linear Regression:
\hat{y}=\beta_0+\beta_1x_1+\cdots+\beta_kx_k+\varepsilon
‡πÉ‡∏ä‡πâ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç ‡πÄ‡∏ä‡πà‡∏ô ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô, ‡∏£‡∏≤‡∏Ñ‡∏≤
	‚Ä¢	Logistic Regression (‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏•‡∏≤‡∏™ 1):
P(Y{=}1\mid \mathbf{x})=\sigma(\mathbf{w}^\top\mathbf{x})=\frac{1}{1+e^{-\mathbf{w}^\top\mathbf{x}}}
	‚Ä¢	Train/Test Split: ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏∏‡∏î‡∏ù‡∏∂‡∏Å (‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå) ‡πÅ‡∏•‡∏∞‡∏ä‡∏∏‡∏î‡∏ó‡∏î‡∏™‡∏≠‡∏ö (‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏à‡∏£‡∏¥‡∏á)
	‚Ä¢	‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î Overfitting/Underfitting (‡∏Å‡∏•‡πà‡∏≤‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏á‡πà‡∏≤‡∏¢): ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà ‚Äú‡∏à‡∏≥‚Äù ‡∏°‡∏≤‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ vs ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà ‚Äú‡∏á‡πà‡∏≤‡∏¢‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ‚Äù

## Hands-on A (Regression): ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ì‡∏¥‡∏ï‡∏à‡∏≤‡∏Å‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á‡∏≠‡πà‡∏≤‡∏ô


import numpy as np, pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression

np.random.seed(42)

# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏±‡∏á‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå
n = 200
hours = np.random.uniform(0, 16, size=n)
noise = np.random.normal(0, 5, size=n)
math = 30 + 4*hours + noise            # ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÇ‡∏î‡∏¢‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì
math = np.clip(math, 0, 100)           # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏ä‡πà‡∏ß‡∏á‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô 0-100

df_reg = pd.DataFrame({"StudyHours": hours, "Math": math})

# ‡πÅ‡∏ö‡πà‡∏á train/test
X = df_reg[["StudyHours"]]
y = df_reg["Math"]
Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.2, random_state=42)

# ‡∏™‡∏£‡πâ‡∏≤‡∏á baseline ‡πÅ‡∏ö‡∏ö‡∏ó‡∏≤‡∏¢‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢
y_pred_baseline = np.repeat(ytr.mean(), len(yte))

# ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏ä‡∏¥‡∏á‡πÄ‡∏™‡πâ‡∏ô
lr = LinearRegression().fit(Xtr, ytr)
y_pred = lr.predict(Xte)

print("Coefficient (Œ≤1):", lr.coef_[0])
print("Intercept (Œ≤0):", lr.intercept_)

6.4 Hands-on B (Classification): ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢ ‚Äú‡∏ú‡πà‡∏≤‡∏ô/‡πÑ‡∏°‡πà‡∏ú‡πà‡∏≤‡∏ô‚Äù ‡∏à‡∏≤‡∏Å‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á‡∏≠‡πà‡∏≤‡∏ô+‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡πâ‡∏≤‡πÄ‡∏£‡∏µ‡∏¢‡∏ô

# ===== Classification: Pass/Fail from StudyHours & Attendance =====
from sklearn.linear_model import LogisticRegression

np.random.seed(7)
n = 400
hours = np.random.uniform(0, 16, size=n)
attend = np.random.uniform(0.5, 1.0, size=n)   # ‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡πÄ‡∏Ç‡πâ‡∏≤‡πÄ‡∏£‡∏µ‡∏¢‡∏ô 50%‚Äì100%
# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏â‡∏•‡∏≤‡∏Å: ‡∏ú‡πà‡∏≤‡∏ô (1) ‡∏ñ‡πâ‡∏≤ 0.35*hours + 0.8*attend > ‡πÄ‡∏Å‡∏ì‡∏ë‡πå (‡∏°‡∏µ noise)
score = 0.35*hours + 0.8*attend + np.random.normal(0, 0.1, size=n)
y = (score > 0.9).astype(int)

df_clf = pd.DataFrame({"StudyHours": hours, "Attendance": attend, "Pass": y})

X = df_clf[["StudyHours", "Attendance"]]
y = df_clf["Pass"]

Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.2, random_state=7, stratify=y)

# baseline: ‡∏ó‡∏≤‡∏¢‡∏Ñ‡∏•‡∏≤‡∏™‡∏ó‡∏µ‡πà‡∏°‡∏≤‡∏Å‡∏™‡∏∏‡∏î
majority = int(ytr.value_counts().idxmax())
y_pred_base = np.repeat(majority, len(yte))

# Logistic Regression
logreg = LogisticRegression().fit(Xtr, ytr)
y_pred = logreg.predict(Xte)
y_proba = logreg.predict_proba(Xte)[:,1]

print("Coefficients (w):", dict(zip(X.columns, logreg.coef_[0])))
print("Intercept (b):", logreg.intercept_[0])


‚∏ª

## ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏• (Model Evaluation) ‚Äî 30 ‡∏ô‡∏≤‡∏ó‡∏µ

### ‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå (‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏≠‡∏∞‡πÑ‡∏£)
	‚Ä¢	‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏ï‡∏±‡∏ß‡∏ä‡∏µ‡πâ‡∏ß‡∏±‡∏î‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô:
	‚Ä¢	Regression:
\textbf{MAE}=\frac{1}{n}\sum|y-\hat{y}|,
\textbf{RMSE}=\sqrt{\frac{1}{n}\sum(y-\hat{y})^2},
\textbf{R}^2=1-\frac{\sum (y-\hat{y})^2}{\sum (y-\bar{y})^2}
	‚Ä¢	Classification: Accuracy, Precision=\frac{TP}{TP+FP}, Recall=\frac{TP}{TP+FN}, F1=\frac{2PR}{P+R}, Confusion Matrix, ‡πÅ‡∏•‡∏∞‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î ROC-AUC
	‚Ä¢	‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö Baseline vs Model ‡πÅ‡∏•‡∏∞‡πÅ‡∏õ‡∏•‡∏ú‡∏•‡πÄ‡∏ä‡∏¥‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢

### Hands-on A (Regression Metrics + ‡∏Å‡∏£‡∏≤‡∏ü Residual)

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import matplotlib.pyplot as plt

# ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô baseline vs linear regression
mae_base = mean_absolute_error(yte, y_pred_baseline)
rmse_base = mean_squared_error(yte, y_pred_baseline, squared=False)

mae_lr = mean_absolute_error(yte, y_pred)
rmse_lr = mean_squared_error(yte, y_pred, squared=False)
r2_lr = r2_score(yte, y_pred)

print(f"Baseline  MAE={mae_base:.2f}, RMSE={rmse_base:.2f}")
print(f"LinearReg MAE={mae_lr:.2f}, RMSE={rmse_lr:.2f}, R^2={r2_lr:.3f}")

# Residual plot
resid = yte - y_pred
plt.scatter(y_pred, resid)
plt.axhline(0, color="black", linewidth=1)
plt.xlabel("Predicted Math")
plt.ylabel("Residual (y - ≈∑)")
plt.title("Residual Plot (‡∏Ñ‡∏ß‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏£‡∏≠‡∏ö‡∏®‡∏π‡∏ô‡∏¢‡πå‡πÅ‡∏ö‡∏ö‡πÑ‡∏£‡πâ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö)")
plt.show()

‡∏Å‡∏≤‡∏£‡∏ï‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°: ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏î‡∏µ‡∏Ñ‡∏ß‡∏£ MAE/RMSE ‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤ baseline ‡πÅ‡∏•‡∏∞‡∏Å‡∏£‡∏≤‡∏ü residual ‡∏Ñ‡∏ß‡∏£‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô (‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏™‡πâ‡∏ô‡∏ï‡∏£‡∏á‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏õ‡∏£‡∏õ‡∏£‡∏ß‡∏ô‡∏Ñ‡∏á‡∏ó‡∏µ‡πà)

7.3 Hands-on B (Classification Metrics + Confusion Matrix + ROC-AUC)

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, RocCurveDisplay

# Baseline vs Logistic Regression
acc_base = accuracy_score(yte, y_pred_base)
acc = accuracy_score(yte, y_pred)
prec = precision_score(yte, y_pred, zero_division=0)
rec = recall_score(yte, y_pred, zero_division=0)
f1 = f1_score(yte, y_pred, zero_division=0)
auc = roc_auc_score(yte, y_proba)

print(f"Baseline Accuracy: {acc_base:.3f}")
print(f"LogReg   Accuracy: {acc:.3f}, Precision: {prec:.3f}, Recall: {rec:.3f}, F1: {f1:.3f}, ROC-AUC: {auc:.3f}")

# Confusion Matrix
cm = confusion_matrix(yte, y_pred)
print("Confusion Matrix:\n", cm)

# ROC Curve
RocCurveDisplay.from_predictions(yte, y_proba)
plt.title("ROC Curve (‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ï‡πâ‡πÇ‡∏Ñ‡πâ‡∏á‡∏°‡∏≤‡∏Å ‚Üí ‡πÅ‡∏¢‡∏Å‡∏Ñ‡∏•‡∏≤‡∏™‡πÑ‡∏î‡πâ‡∏î‡∏µ)")
plt.show()

‡∏Å‡∏≤‡∏£‡∏ï‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°:
	‚Ä¢	‡∏´‡∏≤‡∏Å Accuracy/Precision/Recall/F1 ‡∏™‡∏π‡∏á‡∏Å‡∏ß‡πà‡∏≤ baseline ‡πÅ‡∏™‡∏î‡∏á‡∏ß‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå‡∏Å‡∏ß‡πà‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏î‡∏≤‡∏™‡∏∏‡πà‡∏°/‡πÄ‡∏î‡∏≤‡∏Ñ‡∏•‡∏≤‡∏™‡∏ó‡∏µ‡πà‡∏°‡∏≤‡∏Å‡∏™‡∏∏‡∏î
	‚Ä¢	ROC-AUC ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏Å‡∏•‡πâ 1 ‡πÅ‡∏õ‡∏•‡∏ß‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏¢‡∏Å‡∏Ñ‡∏•‡∏≤‡∏™‡πÑ‡∏î‡πâ‡∏î‡∏µ‡πÉ‡∏ô‡∏´‡∏•‡∏≤‡∏¢ threshold

‚∏ª

‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏™‡∏∞‡∏ó‡πâ‡∏≠‡∏ô‡∏Ñ‡∏¥‡∏î (Reflection)
	1.	‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì ‡∏ä‡∏ô‡∏∞ baseline ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà? ‡∏ä‡∏ô‡∏∞‡∏°‡∏≤‡∏Å‡∏ô‡πâ‡∏≠‡∏¢‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡πÉ‡∏î‡πÉ‡∏ô‡∏ï‡∏±‡∏ß‡∏ä‡∏µ‡πâ‡∏ß‡∏±‡∏î‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
	2.	‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡∏≤‡∏î‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô (MAE/RMSE) ‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡πà‡∏≤ F1 ‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢‡πÉ‡∏ô‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï‡∏à‡∏£‡∏¥‡∏á ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£ (‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏Å‡∏µ‡πà‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô/‡∏Å‡∏µ‡πà‡πÄ‡∏õ‡∏≠‡∏£‡πå‡πÄ‡∏ã‡πá‡∏ô‡∏ï‡πå‡∏à‡∏∂‡∏á ‚Äú‡∏Ñ‡∏∏‡πâ‡∏°‡∏Ñ‡πà‡∏≤‚Äù)?
	3.	‡∏´‡∏≤‡∏Å‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á residual ‡∏°‡∏µ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö ‡∏´‡∏£‡∏∑‡∏≠ Precision/Recall ‡∏¢‡∏±‡∏á‡∏ï‡πà‡∏≥ ‡∏à‡∏∞ ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á ‡∏≠‡∏∞‡πÑ‡∏£ (‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå, ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°, ‡∏õ‡∏£‡∏±‡∏ö threshold, ‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏≠‡∏∑‡πà‡∏ô)?

‚∏ª

‡∏ä‡∏¥‡πâ‡∏ô‡∏á‡∏≤‡∏ô‡∏™‡πà‡∏á (Deliverables)
	‚Ä¢	‡∏ï‡∏≤‡∏£‡∏≤‡∏á Baseline vs Model (Regression ‡πÅ‡∏•‡∏∞/‡∏´‡∏£‡∏∑‡∏≠ Classification) ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ 4‚Äì6 ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î
	‚Ä¢	‡∏Å‡∏£‡∏≤‡∏ü Residual (Regression) ‡πÅ‡∏•‡∏∞ ROC + Confusion Matrix (Classification)
	‚Ä¢	‡∏¢‡πà‡∏≠‡∏´‡∏ô‡πâ‡∏≤ ‚ÄúKey message‚Äù 1 ‡∏¢‡πà‡∏≠‡∏´‡∏ô‡πâ‡∏≤: ‡∏™‡∏£‡∏∏‡∏õ‡∏ß‡πà‡∏≤‡∏Ñ‡∏ß‡∏£‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ô‡∏µ‡πâ‡πÉ‡∏ô‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‚Äî‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡πÄ‡∏´‡∏ï‡∏∏‡πÉ‡∏î

‚∏ª
‡∏¢‡∏≠‡∏î‡πÄ‡∏¢‡∏µ‡πà‡∏¢‡∏°‡∏Ñ‡∏£‡∏±‡∏ö‚Äî‡∏ú‡∏°‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° ‡πÇ‡∏à‡∏ó‡∏¢‡πå‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ù‡∏∂‡∏Å‡∏ó‡∏≥‡πÇ‡∏°‡πÄ‡∏î‡∏• 2 ‡πÅ‡∏ö‡∏ö (Regression ‡πÅ‡∏•‡∏∞ Classification) ‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢ ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå ‡πÄ‡∏°‡∏ï‡∏£‡∏¥‡∏Å ‡πÅ‡∏•‡∏∞‡πÅ‡∏ô‡∏ß‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏• ‡πÇ‡∏î‡∏¢‡∏™‡∏°‡∏°‡∏∏‡∏ï‡∏¥‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏à‡∏£‡∏¥‡∏á

‚∏ª

‡πÇ‡∏à‡∏ó‡∏¢‡πå‡∏ó‡∏µ‡πà 1 (Regression): ‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡πÑ‡∏≠‡∏®‡∏Å‡∏£‡∏µ‡∏°‡∏£‡∏≤‡∏¢‡∏ß‡∏±‡∏ô

‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢

‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢ ‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏£‡∏≤‡∏¢‡∏ß‡∏±‡∏ô (‡∏ö‡∏≤‡∏ó) ‡∏à‡∏≤‡∏Å‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏™‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏® ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡πÇ‡∏õ‡∏£‡πÇ‡∏°‡∏ä‡∏±‡πà‡∏ô ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡πâ‡∏≤‡∏£‡πâ‡∏≤‡∏ô

‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ)
	‚Ä¢	‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå: temperature_C, humidity_pct, month, is_weekend, is_holiday, promo_budget_thb, foot_traffic, prior_day_sales, date_index
	‚Ä¢	‡πÄ‡∏•‡πÄ‡∏ö‡∏•: sales_thb
	‚Ä¢	‡∏Ç‡∏ô‡∏≤‡∏î‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: 500 ‡πÅ‡∏ñ‡∏ß (‡∏à‡∏≥‡∏•‡∏≠‡∏á‡πÉ‡∏´‡πâ‡πÉ‡∏Å‡∏•‡πâ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡πÑ‡∏ó‡∏¢)

‡πÄ‡∏°‡∏ï‡∏£‡∏¥‡∏Å‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ
	‚Ä¢	MAE, RMSE, ‡πÅ‡∏•‡∏∞ R¬≤

‡πÅ‡∏ô‡∏ß‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå
	1.	EDA: Histogram/KDE ‡∏Ç‡∏≠‡∏á‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢, Scatter ‡∏Ç‡∏≠‡∏á temperature_C/foot_traffic ‡∏Å‡∏±‡∏ö sales_thb, ‡∏ï‡∏£‡∏ß‡∏à‡∏Ñ‡∏ß‡∏≤‡∏°‡πÇ‡∏Ñ‡πâ‡∏á‡∏á‡∏≠ (non-linearity)
	2.	‡πÇ‡∏°‡πÄ‡∏î‡∏• baseline: ‡∏ó‡∏≤‡∏¢‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢
	3.	‡πÇ‡∏°‡πÄ‡∏î‡∏•: Linear Regression (‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô) ‚Üí ‡∏•‡∏≠‡∏á PolynomialFeatures ‡πÄ‡∏â‡∏û‡∏≤‡∏∞ temperature_C ‡∏´‡∏£‡∏∑‡∏≠ Tree/RandomForest ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏ä‡∏¥‡∏á‡πÄ‡∏™‡πâ‡∏ô
	4.	‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô: Train/Test split, ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô MAE/RMSE/R¬≤, ‡∏ï‡∏£‡∏ß‡∏à residual plot

‚∏ª

‡πÇ‡∏à‡∏ó‡∏¢‡πå‡∏ó‡∏µ‡πà 2 (Classification): ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏™‡∏°‡∏±‡∏Ñ‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÅ‡∏≠‡∏õ (Signup Conversion)

‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢

‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ß‡πà‡∏≤ session ‡∏ô‡∏µ‡πâ ‡∏™‡∏°‡∏±‡∏Ñ‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à (1) ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà (0)

‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ)
	‚Ä¢	‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå: session_duration_s, pages_viewed, device(mobile/desktop/tablet), referral(ads/seo/email/direct), country(TH/VN/ID/SG), is_weekend, clicks_cta, returning_user
	‚Ä¢	‡πÄ‡∏•‡πÄ‡∏ö‡∏•: signed_up ‚àà {0,1}
	‚Ä¢	‡∏Ç‡∏ô‡∏≤‡∏î‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: 2,000 ‡πÅ‡∏ñ‡∏ß

‡πÄ‡∏°‡∏ï‡∏£‡∏¥‡∏Å‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ
	‚Ä¢	Accuracy, Precision/Recall/F1, ‡πÅ‡∏•‡∏∞ ROC-AUC

‡πÅ‡∏ô‡∏ß‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå
	1.	EDA: ‡∏≠‡∏±‡∏ï‡∏£‡∏≤ signup ‡πÇ‡∏î‡∏¢ device/referral, distribution ‡∏Ç‡∏≠‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ö‡∏ô‡∏´‡∏ô‡πâ‡∏≤, correlation ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏ä‡∏¥‡∏á‡∏õ‡∏£‡∏¥‡∏°‡∏≤‡∏ì
	2.	Baseline: ‡∏ó‡∏≤‡∏¢‡∏Ñ‡∏•‡∏≤‡∏™‡∏ó‡∏µ‡πà‡∏°‡∏≤‡∏Å‡∏™‡∏∏‡∏î
	3.	‡πÇ‡∏°‡πÄ‡∏î‡∏•: Logistic Regression (‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô) ‚Üí ‡∏•‡∏≠‡∏á Tree/RandomForest + one-hot ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà
	4.	‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô: Confusion Matrix, ROC-AUC, ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå threshold (Precision-Recall trade-off)

‚∏ª

‡∏•‡∏¥‡∏á‡∏Å‡πå‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå (CSV)
	‚Ä¢	üìÇ Regression: Ice-cream Sales ‚Äì (‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÉ‡∏ô‡∏™‡∏†‡∏≤‡∏û‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°‡∏ô‡∏µ‡πâ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏î‡πâ)
sandbox:/mnt/data/icecream_sales_regression.csv
	‚Ä¢	üìÇ Classification: App Signup Conversion ‚Äì (‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÉ‡∏ô‡∏™‡∏†‡∏≤‡∏û‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°‡∏ô‡∏µ‡πâ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏î‡πâ)
sandbox:/mnt/data/app_signup_classification.csv

‡∏´‡∏≤‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ ‡∏ú‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏ô‡∏ö Notebook ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÇ‡∏à‡∏ó‡∏¢‡πå (‡∏£‡∏ß‡∏°‡πÇ‡∏Ñ‡πâ‡∏î EDA ‚Üí Baseline ‚Üí ‡πÇ‡∏°‡πÄ‡∏î‡∏• ‚Üí Evaluation ‚Üí ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•) ‡πÉ‡∏´‡πâ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏£‡∏±‡∏ô‡πÑ‡∏î‡πâ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ

‚∏ª

‡πÇ‡∏Ñ‡πâ‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏ï‡πâ‡∏ô‡∏™‡∏±‡πâ‡∏ô ‡πÜ (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏≥‡∏ó‡∏±‡∏ô‡∏ó‡∏µ)

Regression (Linear Regression)

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

df = pd.read_csv("icecream_sales_regression.csv", parse_dates=["date_index"])

X = df[["temperature_C","humidity_pct","is_weekend","is_holiday",
        "promo_budget_thb","foot_traffic","prior_day_sales","month"]]
y = df["sales_thb"]

Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.2, random_state=42)

lr = LinearRegression().fit(Xtr, ytr)
yp = lr.predict(Xte)

print("MAE:", mean_absolute_error(yte, yp))
print("RMSE:", mean_squared_error(yte, yp, squared=False))
print("R^2:", r2_score(yte, yp))

Classification (Logistic Regression)

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score

df = pd.read_csv("app_signup_classification.csv")

num_cols = ["session_duration_s","pages_viewed","clicks_cta","is_weekend","returning_user"]
cat_cols = ["device","referral","country"]

X = df[num_cols + cat_cols]
y = df["signed_up"]

pre = ColumnTransformer([
    ("cat", OneHotEncoder(handle_unknown="ignore"), cat_cols),
    ("num", "passthrough", num_cols)
])

clf = Pipeline([
    ("pre", pre),
    ("logit", LogisticRegression(max_iter=1000))
])

Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
clf.fit(Xtr, ytr)

yp = clf.predict(Xte)
yp_prob = clf.predict_proba(Xte)[:,1]

acc = accuracy_score(yte, yp)
prec, rec, f1, _ = precision_recall_fscore_support(yte, yp, average="binary", zero_division=0)
auc = roc_auc_score(yte, yp_prob)

print(f"ACC={acc:.3f}, P={prec:.3f}, R={rec:.3f}, F1={f1:.3f}, AUC={auc:.3f}")


‚∏ª

‡∏ä‡∏¥‡πâ‡∏ô‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡∏™‡πà‡∏á (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥)
	‚Ä¢	‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏°‡∏ï‡∏£‡∏¥‡∏Å (Baseline vs ‡πÇ‡∏°‡πÄ‡∏î‡∏•)
	‚Ä¢	‡∏Å‡∏£‡∏≤‡∏ü‡πÄ‡∏™‡∏£‡∏¥‡∏° 1‚Äì2 ‡∏†‡∏≤‡∏û/‡πÇ‡∏à‡∏ó‡∏¢‡πå (‡πÄ‡∏ä‡πà‡∏ô Residual plot ‡∏´‡∏£‡∏∑‡∏≠ ROC)
	‚Ä¢	‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° Key takeaway 3‚Äì5 ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î ‡∏ß‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ñ‡∏ß‡∏£‡∏ô‡∏≥‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡∏à‡∏£‡∏¥‡∏á‡∏´‡∏£‡∏∑‡∏≠‡∏¢‡∏±‡∏á ‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏≠‡∏∞‡πÑ‡∏£‡∏ï‡πà‡∏≠

‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ‡∏ú‡∏°‡πÄ‡∏û‡∏¥‡πà‡∏° ‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡πÉ‡∏´‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô (Rubric) ‡∏´‡∏£‡∏∑‡∏≠ ‡πÉ‡∏ö‡∏á‡∏≤‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ô‡∏±‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ô ‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏™‡∏≠‡∏á‡πÇ‡∏à‡∏ó‡∏¢‡πå‡∏ô‡∏µ‡πâ‡∏î‡πâ‡∏ß‡∏¢‡πÑ‡∏´‡∏°‡∏Ñ‡∏£‡∏±‡∏ö?

‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏Ñ‡∏∑‡∏≠ ‚Äú‡πÅ‡∏ú‡∏ô‡∏™‡∏≠‡∏ô + ‡∏†‡∏≤‡∏Ñ‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥‚Äù ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡πÇ‡∏à‡∏ó‡∏¢‡πå Regression (‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡πÑ‡∏≠‡∏®‡∏Å‡∏£‡∏µ‡∏°) ‡πÅ‡∏•‡∏∞ Classification (‡∏™‡∏°‡∏±‡∏Ñ‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÅ‡∏≠‡∏õ) ‡∏°‡∏≤‡∏ï‡πà‡∏≠‡∏¢‡∏≠‡∏î‡πÉ‡∏ô‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏ó‡∏µ‡πà 8: ‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡πà‡∏≤‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Storytelling with Data)

‚∏ª

‡∏Å‡∏£‡∏≠‡∏ö‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î (‡∏¢‡πà‡∏≠)

Key message ‚Üí Evidence ‚Üí Visual ‚Üí Annotation ‚Üí Decision
	1.	‡∏ô‡∏¥‡∏¢‡∏≤‡∏° ‚Äú‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å (Key message)‚Äù ‡πÉ‡∏´‡πâ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô
	2.	‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Å‡∏£‡∏≤‡∏ü‡∏ó‡∏µ‡πà ‚Äú‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡∏±‡πâ‡∏ô‚Äù ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á
	3.	‡∏•‡∏î‡∏™‡∏¥‡πà‡∏á‡∏£‡∏ö‡∏Å‡∏ß‡∏ô (declutter) ‡πÅ‡∏•‡∏∞ ‡πÑ‡∏Æ‡πÑ‡∏•‡∏ï‡πå ‡∏à‡∏∏‡∏î‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
	4.	‡∏õ‡∏¥‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏î‡πâ‡∏ß‡∏¢ ‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏≠‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á

‚∏ª

A) ‡∏Å‡∏£‡∏ì‡∏µ Regression: ‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡πÑ‡∏≠‡∏®‡∏Å‡∏£‡∏µ‡∏° (Ice-cream Sales)

1) ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏•‡∏±‡∏Å (‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á)
	‚Ä¢	‚Äú‡∏™‡∏∏‡∏î‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå/‡∏ß‡∏±‡∏ô‡∏´‡∏¢‡∏∏‡∏î ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏∂‡πâ‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏ô‡∏±‡∏¢‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç ‡πÅ‡∏•‡∏∞‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡πÄ‡∏Å‡∏¥‡∏î‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡∏≠‡∏∏‡∏ì‡∏´‡∏†‡∏π‡∏°‡∏¥‡πÉ‡∏Å‡∏•‡πâ ~33 ¬∞C (‡∏£‡πâ‡∏≠‡∏ô‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏•‡∏î)‚Äù

2) ‡∏£‡∏π‡∏õ‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏•‡πà‡∏≤‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥)
	‚Ä¢	Bar chart: ‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏° is_weekend, is_holiday (‡πÄ‡∏´‡πá‡∏ô uplift ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô)
	‚Ä¢	Scatter + ‡πÄ‡∏™‡πâ‡∏ô‡πÇ‡∏Ñ‡πâ‡∏á‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏≠‡∏á: temperature_C vs sales_thb ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏∑‡πà‡∏≠ ‚Äú‡∏à‡∏∏‡∏î‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‚Äù ‡∏Ç‡∏≠‡∏á‡∏≠‡∏∏‡∏ì‡∏´‡∏†‡∏π‡∏°‡∏¥

3) ‡πÇ‡∏Ñ‡πâ‡∏î (Notebook-ready; ‡πÉ‡∏ä‡πâ matplotlib ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î)

import pandas as pd, numpy as np
import matplotlib.pyplot as plt

# 0) ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
df = pd.read_csv("icecream_sales_regression.csv", parse_dates=["date_index"])

# 1) Bar: ‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡πÅ‡∏¢‡∏Å weekend/holiday
grp = df.groupby(["is_weekend","is_holiday"])["sales_thb"].mean().reset_index()
labels = ["Wknd0-Hol0","Wknd1-Hol0","Wknd0-Hol1","Wknd1-Hol1"]
x = np.arange(len(labels))
vals = [
    grp[(grp.is_weekend==0)&(grp.is_holiday==0)]["sales_thb"].values[0],
    grp[(grp.is_weekend==1)&(grp.is_holiday==0)]["sales_thb"].values[0],
    grp[(grp.is_weekend==0)&(grp.is_holiday==1)]["sales_thb"].values[0],
    grp[(grp.is_weekend==1)&(grp.is_holiday==1)]["sales_thb"].values[0],
]

plt.figure(figsize=(6,4))
plt.bar(x, vals)
for i,v in enumerate(vals):
    plt.text(i, v, f"{v:.0f}", ha="center", va="bottom")
plt.xticks(x, labels)
plt.title("Average Sales by Weekend/Holiday")
plt.xlabel("Group"); plt.ylabel("Avg Sales (THB)")
plt.show()

# 2) Scatter + ‡πÇ‡∏Ñ‡πâ‡∏á‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏≠‡∏á: ‡∏≠‡∏∏‡∏ì‡∏´‡∏†‡∏π‡∏°‡∏¥‡∏Å‡∏±‡∏ö‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢
T = df["temperature_C"].values
Y = df["sales_thb"].values
coef = np.polyfit(T, Y, 2)          # fit ‡πÇ‡∏Ñ‡πâ‡∏á 2nd degree
poly = np.poly1d(coef)
T_line = np.linspace(T.min(), T.max(), 200)
Y_line = poly(T_line)

# ‡∏à‡∏∏‡∏î‡∏¢‡∏≠‡∏î‡∏Ç‡∏≠‡∏á‡∏û‡∏≤‡∏£‡∏≤‡πÇ‡∏ö‡∏•‡∏≤ (vertex) = -b/(2a)
a,b,c = coef
T_opt = -b/(2*a); Y_opt = poly(T_opt)

plt.figure(figsize=(6,4))
plt.scatter(T, Y, s=10, alpha=0.6)
plt.plot(T_line, Y_line)
plt.scatter([T_opt], [Y_opt], s=50)
plt.annotate(f"Sweet spot ‚âà {T_opt:.1f}¬∞C",
             xy=(T_opt, Y_opt), xytext=(T_opt+0.5, Y_opt+150),
             arrowprops=dict(arrowstyle="->"))
plt.title("Temperature vs Sales with Quadratic Fit")
plt.xlabel("Temperature (¬∞C)"); plt.ylabel("Sales (THB)")
plt.show()

4) ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏™‡∏£‡∏∏‡∏õ‡∏ö‡∏ô‡∏™‡πÑ‡∏•‡∏î‡πå (‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á)
	‚Ä¢	‚Äú‡∏Ç‡∏≤‡∏¢‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡πÉ‡∏ô ‡∏™‚Äì‡∏≠‡∏≤ ‡πÅ‡∏•‡∏∞‡∏ß‡∏±‡∏ô‡∏´‡∏¢‡∏∏‡∏î (+xxx ‡∏ö‡∏≤‡∏ó‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢/‡∏ß‡∏±‡∏ô) ‚Üí ‡∏Ñ‡∏ß‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏™‡∏ï‡πá‡∏≠‡∏Å/‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏ä‡πà‡∏ß‡∏á‡∏î‡∏±‡∏á‡∏Å‡∏•‡πà‡∏≤‡∏ß‚Äù
	‚Ä¢	‚Äú‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡πÉ‡∏Å‡∏•‡πâ ~33 ¬∞C ‚Üí ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÅ‡∏Ñ‡∏°‡πÄ‡∏õ‡∏ç‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡πÄ‡∏Ç‡πâ‡∏≤‡πÇ‡∏ã‡∏ô‡∏ô‡∏µ‡πâ‚Äù

‚∏ª

B) ‡∏Å‡∏£‡∏ì‡∏µ Classification: ‡∏™‡∏°‡∏±‡∏Ñ‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÅ‡∏≠‡∏õ (App Signup Conversion)

1) ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏•‡∏±‡∏Å (‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á)
	‚Ä¢	‚Äú‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡∏õ‡∏∏‡πà‡∏° B ‡πÄ‡∏û‡∏¥‡πà‡∏° CR ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö A ‡πÅ‡∏•‡∏∞‡πÇ‡∏°‡πÄ‡∏î‡∏• Logistic ‡πÅ‡∏¢‡∏Å‡∏Ñ‡∏•‡∏≤‡∏™‡πÑ‡∏î‡πâ‡∏î‡∏µ (ROC-AUC ‡∏™‡∏π‡∏á) ‡πÇ‡∏î‡∏¢ SEO/‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÄ‡∏î‡∏¥‡∏° ‡∏°‡∏µ‡πÇ‡∏≠‡∏Å‡∏≤‡∏™‡∏™‡∏°‡∏±‡∏Ñ‡∏£‡∏™‡∏π‡∏á‡∏Å‡∏ß‡πà‡∏≤‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏≠‡∏∑‡πà‡∏ô‚Äù

2) ‡∏£‡∏π‡∏õ‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏•‡πà‡∏≤‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥)
	‚Ä¢	Bar chart: Conversion rate ‡∏Ç‡∏≠‡∏á variant A vs B (‡πÉ‡∏™‡πà‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏ö‡∏ô‡πÅ‡∏ó‡πà‡∏á)
	‚Ä¢	Confusion matrix (‡∏´‡∏•‡∏±‡∏á‡∏ï‡∏±‡πâ‡∏á threshold ‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô 0.5) ‡πÅ‡∏•‡∏∞ ROC curve (‡πÅ‡∏™‡∏î‡∏á AUC)

3) ‡πÇ‡∏Ñ‡πâ‡∏î (Notebook-ready)

import pandas as pd, numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, RocCurveDisplay, roc_auc_score

# 0) ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
df = pd.read_csv("app_signup_classification.csv")

# 1) ‡πÅ‡∏™‡∏î‡∏á CR A vs B
cr = df.groupby("referral")["signed_up"].mean()  # ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á insight ‡∏≠‡∏∑‡πà‡∏ô
tab = df.groupby("device")["signed_up"].mean()

cr_var = df.groupby(df.index // 1)  # placeholder ‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ per-session ‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
cr_AB = df.assign(variant=np.where(np.random.rand(len(df))<0.5,"A","B")) \
          .groupby("variant")["signed_up"].mean()

labels = list(cr_AB.index); vals = [100*v for v in cr_AB.values]  # %
x = np.arange(len(labels))
plt.figure(figsize=(5,4))
plt.bar(x, vals)
for i,v in enumerate(vals):
    plt.text(i, v, f"{v:.1f}%", ha="center", va="bottom")
plt.xticks(x, labels)
plt.ylabel("Conversion Rate (%)"); plt.title("CR by Variant")
plt.show()

# 2) ‡πÇ‡∏°‡πÄ‡∏î‡∏• + ROC/Confusion
num = ["session_duration_s","pages_viewed","clicks_cta","is_weekend","returning_user"]
cat = ["device","referral","country"]
X = df[num+cat]; y = df["signed_up"]

pipe = Pipeline([
    ("prep", ColumnTransformer([
        ("cat", OneHotEncoder(handle_unknown="ignore"), cat),
        ("num", "passthrough", num)
    ])),
    ("clf", LogisticRegression(max_iter=1000))
])

Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)
pipe.fit(Xtr, ytr)
proba = pipe.predict_proba(Xte)[:,1]
pred = (proba>=0.5).astype(int)

# Confusion matrix
cm = confusion_matrix(yte, pred)
plt.figure(figsize=(4,4))
plt.imshow(cm, cmap="Blues")
for i in range(2):
    for j in range(2):
        plt.text(j, i, cm[i,j], ha="center", va="center")
plt.xticks([0,1], ["Pred 0","Pred 1"])
plt.yticks([0,1], ["True 0","True 1"])
plt.title("Confusion Matrix (Threshold=0.5)")
plt.show()

# ROC
RocCurveDisplay.from_predictions(yte, proba)
auc = roc_auc_score(yte, proba)
plt.title(f"ROC Curve (AUC = {auc:.3f})")
plt.show()

4) ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏™‡∏£‡∏∏‡∏õ‡∏ö‡∏ô‡∏™‡πÑ‡∏•‡∏î‡πå (‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á)
	‚Ä¢	‚ÄúB ‡∏ä‡∏ô‡∏∞ A (CR ‡∏™‡∏π‡∏á‡∏Å‡∏ß‡πà‡∏≤ X.X ‡∏à‡∏∏‡∏î‡∏£‡πâ‡∏≠‡∏¢‡∏•‡∏∞); ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ä‡πà‡∏ß‡∏¢‡∏ö‡πà‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÇ‡∏≠‡∏Å‡∏≤‡∏™‡∏™‡∏π‡∏á (AUC ‚âà 0.8+) ‚Üí ‡πÇ‡∏ü‡∏Å‡∏±‡∏™ SEO/‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÄ‡∏î‡∏¥‡∏°‚Äù
	‚Ä¢	‚Äú‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥: Rollout ‡πÅ‡∏ö‡∏ö phased + ‡πÄ‡∏ù‡πâ‡∏≤‡∏£‡∏∞‡∏ß‡∏±‡∏á guardrails (‡πÄ‡∏ä‡πà‡∏ô complaint rate)‚Äù

‚∏ª

‡πÄ‡∏Ñ‡∏•‡πá‡∏î‡∏•‡∏±‡∏ö‡∏™‡πÑ‡∏•‡∏î‡πå ‚Äú‡πÄ‡∏•‡πà‡∏≤‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÉ‡∏ô 1 ‡∏´‡∏ô‡πâ‡∏≤‚Äù
	‚Ä¢	‡∏´‡∏±‡∏ß‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á = Key message (‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏ä‡∏∑‡πà‡∏≠‡∏Å‡∏£‡∏≤‡∏ü)
	‚Ä¢	‡∏ã‡πâ‡∏≤‡∏¢: ‡∏Å‡∏£‡∏≤‡∏ü‡∏´‡∏•‡∏±‡∏Å 1‚Äì2 ‡∏†‡∏≤‡∏û (declutter) + annotation ‡∏ä‡∏µ‡πâ‡∏à‡∏∏‡∏î‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
	‚Ä¢	‡∏Ç‡∏ß‡∏≤: ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏´‡∏•‡∏±‡∏Å 3‚Äì5 ‡∏Ñ‡πà‡∏≤ (‡πÄ‡∏ä‡πà‡∏ô Avg uplift, CR, AUC, CI/p-value)
	‚Ä¢	‡∏•‡πà‡∏≤‡∏á: Decision ‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡πÑ‡∏î‡πâ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ + ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á/‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î 2‚Äì3 ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î

‚∏ª

‡∏á‡∏≤‡∏ô‡∏°‡∏≠‡∏ö‡∏´‡∏°‡∏≤‡∏¢ (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ô‡∏±‡∏Å‡∏®‡∏∂‡∏Å‡∏©‡∏≤)
	1.	‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Å‡∏£‡∏ì‡∏µ (‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢ / ‡∏™‡∏°‡∏±‡∏Ñ‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô) ‚Üí ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô Key message 1 ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î
	2.	‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü 2 ‡∏†‡∏≤‡∏û‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ ‡∏û‡∏£‡πâ‡∏≠‡∏° annotation
	3.	‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô ‚Äú‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏≠‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‚Äù ‡πÅ‡∏•‡∏∞ ‚Äú‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‚Äù ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞ ‚â§3 ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î
	4.	‡∏™‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πÑ‡∏•‡∏î‡πå 1 ‡∏´‡∏ô‡πâ‡∏≤ ‡∏´‡∏£‡∏∑‡∏≠‡πÇ‡∏ô‡πâ‡∏ï‡∏ö‡∏∏‡πä‡∏Å 1 ‡πÑ‡∏ü‡∏•‡πå (‡∏°‡∏µ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏£‡∏≤‡∏ü‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÉ‡∏ï‡πâ‡∏£‡∏π‡∏õ)

‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢‡∏Ñ‡∏∑‡∏≠‡πÉ‡∏´‡πâ‡∏ô‡∏±‡∏Å‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡∏°‡∏≠‡∏á‡πÄ‡∏´‡πá‡∏ô‡∏ß‡πà‡∏≤ ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÄ‡∏ä‡∏¥‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç ‡∏à‡∏∞ ‚Äú‡∏ó‡∏£‡∏á‡∏û‡∏•‡∏±‡∏á‚Äù ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ñ‡∏π‡∏Å‡πÄ‡∏•‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á ‡∏ó‡∏µ‡πà‡∏ô‡∏≥‡πÑ‡∏õ‡∏™‡∏π‡πà ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à ‡πÑ‡∏î‡πâ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ.

